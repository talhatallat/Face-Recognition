
#--------------------Facedetection.py-----from caturing camera------------------------
import numpy as np
import cv2


faceCascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')


cap = cv2.VideoCapture(0) # captures video
cap.set(3,640)# set Width to 640
cap.set(4,480)# set Height to 480

while True: #stays on until we break it
    ret, img = cap.read() # Reading every signal frame from the video capture
    
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) # converts the resize colour image to grayscale
    
    faces = faceCascade.detectMultiScale( # parameters that will vary depending on the size of the image
            gray, scaleFactor=1.01, minNeighbors=10, minSize=(30,30)) 

    for (x,y,w,h) in faces: #face detection rectanle/box around the face
        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2)
        roi_gray = gray[y:y+h, x:x+w]
        roi_color = img[y:y+h, x:x+w]  
    cv2.imshow('Video',img)
    B = cv2.waitKey(2) & 0xff
    if B == 27: #Press 'ESC' to quit
        break
    
cap.release()
cv2.destroyAllWindows()




#----------------------faceDetection_image.py---------from an image--------------------------
import numpy as np
import cv2


faceCascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')


cap = cv2.VideoCapture(0) # captures video
cap.set(3,640)# set Width to 640
cap.set(4,480)# set Height to 480

while True: #stays on until we break it
    ret, img = cap.read() # Reading every signal frame from the video capture
    
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) # converts the resize colour image to grayscale
    
    faces = faceCascade.detectMultiScale( # parameters that will vary depending on the size of the image
            gray, scaleFactor=1.01, minNeighbors=10, minSize=(30,30)) 

    for (x,y,w,h) in faces: #face detection rectanle/box around the face
        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2)
        roi_gray = gray[y:y+h, x:x+w]
        roi_color = img[y:y+h, x:x+w]  
    cv2.imshow('Video',img)
    B = cv2.waitKey(2) & 0xff
    if B == 27: #Press 'ESC' to quit
        break
    
cap.release()
cv2.destroyAllWindows()


















#---------------FACE RECOGNITION------------------------
import cv2
import os
import numpy as np

def faceDetection(test_img):
    gray_img=cv2.cvtColor(test_img,cv2.COLOR_BGR2GRAY)
    face_haar_cascade=cv2.CascadeClassifier('haarcascade_frontalface_default.xml')
    faces=face_haar_cascade.detectMultiScale(gray_img,scaleFactor=1.32,minNeighbors=10,minSize=(30,30),flags=0)

    return faces,gray_img

def ID_for_training_database(directory):
    faces=[]
    faceID=[]

    for path,subdirnames,filenames in os.walk(directory):
        for filename in filenames:
            if filename.startswith("."):
                print("Skipping system file")#Skipping files that startwith .
                continue
           
            id=os.path.basename(path)
            img_path = os.path.join(path, filename)
            print("img_path:",img_path)
            print("id:",id)
            test_img = cv2.imread(img_path)
            if test_img is None:
                print("Image not loaded properly")
                continue
            faces_rect,gray_img = faceDetection(test_img) #Calling faceDetection function to return faces detected in particular image
            if len(faces_rect)!=1:
               continue #Since we are assuming only single person images are being fed to classifier
            (x,y,w,h)=faces_rect[0]
            roi_gray=gray_img[y:y+w,x:x+h] #cropping region of interest i.e. face area from grayscale image
            faces.append(roi_gray)
            faceID.append(int(id))
    return faces,faceID


def train_classifier(faces,faceID):
    face_recognizer=cv2.face.LBPHFaceRecognizer_create()
    face_recognizer.train(faces,np.array(faceID))
    return face_recognizer

def draw_rect(test_img,face):
    (x,y,w,h)=face
    cv2.rectangle(test_img,(x,y),(x+w,y+h),(0,0,255),thickness=2)


def put_text(test_img,text,x,y):
    cv2.putText(test_img,text,(x,y),cv2.FONT_HERSHEY_DUPLEX,2,(0,0,255),thickness=2)




#---------------------Image_test.py---------TESTING AN IMAGE FOR RECOGNITION---------------
import cv2
import os
import numpy as np
import faceRecognition as fr

test_img = cv2.imread('testimages\Kangana.jpg')#test_img path
faces_detected,gray_img = fr.faceDetection(test_img)
print("faces_detected:",faces_detected)


faces,faceID = fr.ID_for_training_database('Database_trainingimages')
face_recognizer = fr.train_classifier(faces,faceID)
face_recognizer.write('trainingData.yml')

name={0:"Talha",1:"Priyanka", 2: "Kangana"} 


for face in faces_detected:
    (x,y,w,h) = face
    roi_gray = gray_img[y:y+h,x:x+h]
    ID,confidence = face_recognizer.predict(roi_gray)
    print("Confidence: ",confidence)
    print("ID: ",ID)
    fr.draw_rect(test_img,face)
    predicted_name = name[ID]
    if(confidence>42): 
        continue
    fr.put_text(test_img,predicted_name,x,y)

resized_img=cv2.resize(test_img,(640,480))
cv2.imshow("face Recognition",resized_img)
cv2.waitKey(0)
cv2.destroyAllWindows


#-------------------------tester.py-----Recognition main for capturing camera----------------------------
import os
import cv2
import numpy as np #library renames to fr
import faceRecognition as fr #class renames to fr


#This module captures images via webcam and performs face recognition
face_recognizer = cv2.face.LBPHFaceRecognizer_create() # LBPH Recognizer
face_recognizer.read('trainingData.yml')# Load saved training data

name = {0:"Talha",1:"Priyanka", 2: "Kangana"} # id's from 0 to 2 with names


cap=cv2.VideoCapture(0) # captures video
cap.set(3,640)# Width
cap.set(4,480)# Height

while True:
    ret,test_img=cap.read()# captures frame and returns boolean value and captured image
    faces_detected,gray_img=fr.faceDetection(test_img)# using faceDetection function from fr which uses all the paremeters 


    for (x,y,w,h) in faces_detected: 
      cv2.rectangle(test_img,(x,y),(x+w,y+h),(0,0,255),thickness=2) 

    resized_img = cv2.resize(test_img, (640, 480))
    cv2.imshow('Face Detection',resized_img) #shoes 'Face Detected' resized image
    cv2.waitKey(10)


    for face in faces_detected:
        (x,y,w,h) = face
        roi_gray = gray_img[y:y+w, x:x+h]
        ID,confidence = face_recognizer.predict(roi_gray)#predicting the id of given image
        print("Confidence: ",confidence)
        print("ID: ",ID)
        fr.draw_rect(test_img, face)
        predicted_name = name[ID]
        
       
        if confidence < 40:#If confidence less than 37 then don't print predicted face text on screen
           fr.put_text(test_img,predicted_name,x,y)
          


    resized_img = cv2.resize(test_img, (640, 480))
    cv2.imshow('Face Recognition',resized_img)
    if cv2.waitKey(10) == ord('b'):#wait until 'b' key is pressed
        break


cap.release()
cv2.destroyAllWindows





















